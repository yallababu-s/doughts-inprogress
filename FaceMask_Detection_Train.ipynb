{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f048fe72-5e4e-4a49-8f96-e086d9cb3c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras in c:\\users\\hp\\anaconda3\\envs\\vetens\\lib\\site-packages (2.10.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement 2.12.0 (from versions: none)\n",
      "ERROR: No matching distribution found for 2.12.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\envs\\vetens\\lib\\site-packages (1.24.4)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement 1.24.3 (from versions: none)\n",
      "ERROR: No matching distribution found for 1.24.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: opencv-python in c:\\users\\hp\\anaconda3\\envs\\vetens\\lib\\site-packages (4.10.0.84)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement 4.10.0.84 (from versions: none)\n",
      "ERROR: No matching distribution found for 4.10.0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\anaconda3\\envs\\vetens\\lib\\site-packages (2.10.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement 2.12.1 (from versions: none)\n",
      "ERROR: No matching distribution found for 2.12.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Matplotlib in c:\\users\\hp\\anaconda3\\envs\\vetens\\lib\\site-packages (3.10.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement 3.9.4 (from versions: none)\n",
      "ERROR: No matching distribution found for 3.9.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: imutils in c:\\users\\hp\\anaconda3\\envs\\vetens\\lib\\site-packages (0.5.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement 0.5.3 (from versions: none)\n",
      "ERROR: No matching distribution found for 0.5.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras in c:\\users\\hp\\anaconda3\\envs\\vetens\\lib\\site-packages (2.10.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement 2.12.0 (from versions: none)\n",
      "ERROR: No matching distribution found for 2.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install Keras 2.12.0\n",
    "!pip install numpy 1.24.3\n",
    "!pip install opencv-python 4.10.0.84\n",
    "!pip install tensorflow 2.12.1\n",
    "!pip install Matplotlib 3.9.4\n",
    "!pip install imutils 0.5.3\n",
    "!pip install Keras 2.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e0fe6bf-c154-474e-a637-9a58dee11fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# python train_mask_detector.py --dataset dataset\n",
    "\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af1ea33d-fde7-4ecf-a7b0-a70fda55dcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the initial learning rate, number of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 10\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "544f963a-eaa3-4b06-8392-d9408cd3bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r before string will prevent Python from interpreting escape characters.\n",
    "DIRECTORY = r\"D:\\HopeAI\\Facemask DL project yogana\\dataset\"\n",
    "CATEGORIES = [\"with_mask\", \"without_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aec42290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "print(\"[INFO] loading images...\")\n",
    "\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdc5ea56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3848 images.\n",
      "Example image paths:\n",
      "['D:\\\\HopeAI\\\\Facemask DL project yogana\\\\dataset\\\\without_mask\\\\0.jpg', 'D:\\\\HopeAI\\\\Facemask DL project yogana\\\\dataset\\\\without_mask\\\\0_0_aidai_0014.jpg', 'D:\\\\HopeAI\\\\Facemask DL project yogana\\\\dataset\\\\without_mask\\\\0_0_aidai_0029.jpg', 'D:\\\\HopeAI\\\\Facemask DL project yogana\\\\dataset\\\\without_mask\\\\0_0_aidai_0043.jpg', 'D:\\\\HopeAI\\\\Facemask DL project yogana\\\\dataset\\\\without_mask\\\\0_0_aidai_0074.jpg']\n"
     ]
    }
   ],
   "source": [
    "from imutils import paths\n",
    "\n",
    "# Define the path to your dataset\n",
    "dataset_path = r\"D:\\HopeAI\\Facemask DL project yogana\\dataset\"\n",
    "\n",
    "# List all image paths in the dataset\n",
    "imagePaths = list(paths.list_images(dataset_path))\n",
    "\n",
    "# Print the number of images found and a few example paths\n",
    "print(f\"Found {len(imagePaths)} images.\")\n",
    "print(\"Example image paths:\")\n",
    "print(imagePaths[:5])  # Print first 5 image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26796c07-6efb-4547-913e-aebcf250ea48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (3848, 224, 224, 3)\n",
      "Labels shape: (3848,)\n"
     ]
    }
   ],
   "source": [
    "# Initialize data and labels as lists\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "\t# extract the class label from the filename\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "\t# load the input image (224x224) and preprocess it\n",
    "\timage = load_img(imagePath, target_size=(224, 224))\n",
    "\timage = img_to_array(image)\n",
    "\n",
    "\t# update the data and labels lists, respectively\n",
    "\tdata.append(image)\n",
    "\tlabels.append(label)\n",
    "\n",
    "# Convert the data and labels lists to NumPy arrays\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Data shape:\", data.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1836f430-c98c-4a5f-8654-bf699dbc0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47e2c947-2a50-43b0-9ccf-19881e79044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc07e515-787c-47ff-9704-5249e8559f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3848, 150528)\n"
     ]
    }
   ],
   "source": [
    "data = data.reshape(data.shape[0], -1)\n",
    "print(data.shape)\n",
    "#ValueError: Found array with dim 3. None expected <= 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0421b31-f084-4fdc-8e2f-8a0dc6628f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3848, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8fe46f2-9b72-4256-ba29-b82bcc555aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3848, 6)\n"
     ]
    }
   ],
   "source": [
    "labels = labels.reshape(labels.shape[0], -1)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca7a7db8-70ba-4823-9474-f7c544864384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "956a2fc0-3f99-4f4b-ac7e-a1e4b6637da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d65894f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the validation image generator\n",
    "val_aug = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3797c09e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (3078, 150528))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create data generators\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43maug\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m val_generator \u001b[38;5;241m=\u001b[39m val_aug\u001b[38;5;241m.\u001b[39mflow(testX, testY, batch_size\u001b[38;5;241m=\u001b[39mBS)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\vetens\\lib\\site-packages\\keras\\preprocessing\\image.py:1547\u001b[0m, in \u001b[0;36mImageDataGenerator.flow\u001b[1;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, ignore_class_split, subset)\u001b[0m\n\u001b[0;32m   1488\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow\u001b[39m(\n\u001b[0;32m   1489\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1490\u001b[0m     x,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m     subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1501\u001b[0m ):\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Takes data & label arrays, generates batches of augmented data.\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \n\u001b[0;32m   1504\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1545\u001b[0m \n\u001b[0;32m   1546\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNumpyArrayIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1549\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1550\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_class_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_class_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\vetens\\lib\\site-packages\\keras\\preprocessing\\image.py:758\u001b[0m, in \u001b[0;36mNumpyArrayIterator.__init__\u001b[1;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, ignore_class_split, dtype)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_misc \u001b[38;5;241m=\u001b[39m x_misc\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m--> 758\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    759\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput data in `NumpyArrayIterator` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    760\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould have rank 4. You passed an array \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    761\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith shape\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    762\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m    763\u001b[0m     )\n\u001b[0;32m    764\u001b[0m channels_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[channels_axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m}:\n",
      "\u001b[1;31mValueError\u001b[0m: ('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (3078, 150528))"
     ]
    }
   ],
   "source": [
    "# Create data generators\n",
    "train_generator = aug.flow(trainX, trainY, batch_size=BS)\n",
    "val_generator = val_aug.flow(testX, testY, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d848b09",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_generator\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "train_generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca56f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45daa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the MobileNetV2 network, ensuring the head FC layer sets are\n",
    "# left off\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b041a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a719308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae7040-8055-44c4-b3c8-c48852599490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e461e2e-bdcc-4fe1-bf2e-731262bb4051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile our model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(learning_rate=INIT_LR)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4066cade-65d2-4182-8aca-4764d822f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile our model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(learning_rate=INIT_LR)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54bf47b-eacc-46cb-965c-05d7f6f6f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(testX) // BS,\n",
    "    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6a41ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc56a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a587369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a nicely formatted classification report\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
    "\ttarget_names=lb.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c05e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the model to disk\n",
    "print(\"[INFO] saving mask detector model...\")\n",
    "model.save(\"Face_Mask_Detector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b22465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a44e956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d65b64-a89c-4f03-94dc-372f43f15137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e9fd38-90b8-47d3-8d92-68e6d6b21fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
